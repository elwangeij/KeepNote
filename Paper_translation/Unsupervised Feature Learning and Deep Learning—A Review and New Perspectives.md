
## <center>Unsupervised Feature Learning and Deep Learning: A Review and New Perspectives
## <center>非监督特征学习和深度学习：综述和新视角
<center>**Yoshua Bengio, Aaron Courville, and Pascal Vincent**

**Department of computer science and operations research, U. Montreal**
</center>
<font face="楷体" size=3>
## 摘要
机器学习算法的成功通常依赖于数据表征。我们猜测这是因为不同的数据表征可以隐藏或多或少数据背后不同解释性因素的变量。不仅是专业知识，学习同样也能被用来帮助设计表征。对AI的追求正在促使人们设计更加强大的表征学习算法。本篇文章回顾了非监督特征学习和深度学习领域内最近的工作，包括概率模型、流形学习和深度学习的进展。这激发了一些长期未能回答的问题，这些问题是关于学习好的数据表征、<font color=red>计算表征（即推断）以及表征学习、密度估计和流形学习三者几何关系的合适目标</font>。
##1 介绍
数据表征在经验上被证明是影响大多数机器学习算法表现的核心性因素。因此许多现实中应用机器学习算法的努力都花费在特征提取、预处理和数据变换方面。特征工程是一项重要且费力的任务，这也突出了目前学习算法的劣势：无法从数据中提取所有有用的信息。特征工程是一种方法，其利用人类智慧的优势和先验知识来弥补上述劣势。为了拓宽机器学习应用的范围和简易性，研究学者们特别渴望能够让学习算法较少地依赖于特征工程。这样新的应用才能够被快速的构建，更重要的是让AI更进一步。AI系统必须从根本上理解我们身边的世界，要想实现它需要借助于这样的学习器：该学习器可以识别和解决那些隐藏在观察环境中低级别感知数据背后的解释性因素。
如今实际现实问题已经得到了最先进的结果，特征工程和特征学习相结合的最简单方式就是在人工基础上学习更高级别特征。本文讨论的是特征学习也就是表征学习，比如当建立分类器或其他预测器时，学习数据的表征和转换能够使得人们更容易提取有用的信息。在概率模型下，好的表征通常是那种可以捕获观察输入中隐含解释性因素后验概率的表征。
在不同学习表征的方法中，本文还关注能够产生更非线性和更抽象的表征，即深度学习。深度框架是由多层表征组成，层的数目是一个依赖于实际任务需求的自由参数。本文是早期调查报告的后续和补充【(Bengio, 2009) (but see also Arel et al. (2010))】。这里我们调查了该领域最近的进展，重点是在本研究提出的长期未能回答的问题，尤其是学习好的表征、计算表征（即推断）以及表征学习、密度估计和流行学习三者之间的几何关系的合适目标。
<font color=red>在【Bengio and LeCun (2007)】，我们介绍了AI任务的概念，这对目前机器学习算法是个挑战，涉及到复杂但高度结构化的依赖关系。</font>在具体的AI任务进展中,比如计算机视觉和自然语言理解，如果仅仅依靠简单的参数模型（比如线性模型）看起来希望渺茫。这是因为这些模型不能捕捉到足够多感兴趣点的复杂性。另一方面，机器学习研究人员已经在探索**局部**非线性学习器的灵活性，比如带有一般固定的局部响应核（比如高斯核）的核机器。不幸的是，就像先前【(Bengio and Monperrus, 2005; Bengio et al., 2006a; Bengio and LeCun, 2007; Bengio, 2009; Bengio et al., 2010)】在最后讨论的，大多数这样的算法仅仅是开发了局部泛化的原则，也就是假设将要学的目标方程足够平滑，这样他们可以依赖样本来明确地描绘出目标方程的褶皱。尽管平滑是一个很有用的假设条件，但仍然不足以处理维度灾难。因为这样褶皱（目标方程的上下变化）的数目可能会随着相互作用因素或者输入维度的数目呈指数型增长。我们提倡的是灵活的、非参数的且不仅仅依靠平滑假设的学习算法。但是，将线性模型或者核机器应用在已学到表征之上是有用的：这相当于学习核，即特征空间。核机器是有用的，但是这依赖于恰当相似性度量的先验定义，或者依赖于朴素相似性度量所满足的特征空间。我们也想使用数据来发现好的特征。
> 局部是指x的测试结果绝大部分依赖于训练样本中靠近x的数据。

这使得表征学习作为一个核心元素，能够被吸纳在许多学习框架中。有趣的表征是有表现力的，意味着一个合理大小已学表征能捕捉大量数目的可能输入配置：不包括one-hot representation(独热码)表征，比如传统聚类算法结果；<font color=red>但是包括多聚类算法，几个聚类同时发生或者同一聚类应用在输入的不同部分，比如非常流行的为了目标识别而进行的层次特征提取，这种目标识别是基于图像不同块检测到的聚类种类直方图。</font>【(Lazebnik et al., 2006; Coates and Ng, 2011a)】distributed representation(词向量)和稀疏性表征是能达到如此表现力的两种典型方式，而且两者都能在更多局部方法上提供指数型增益，就像论文3.2节讨论的。【Bengio (2009)】。这是因为每一个参数（例如稀疏编码中某一节点的参数，或者RBM中一个节点）能够被许多样本重复使用，而这些样本不是简单的邻近样本。尽管有局部泛化，输入空间中的不同区域基本上和他们私有参数集相关联，例如在决策树、最近邻、高斯SVM等等。在distributed representation中，指数型级别数目的特征或者隐藏单元的可能子集会被一个给定的输入激活。在单层模型中，每一个特征都特别的与一个偏爱的输入方向相联系，这与输入空间的超平面相对应。和那个输入相联系的编码或者表征就是激活模式（哪个特征与这个输入相对应，以及对应的程度）。这和non-distributed representation相反，比如大多数聚类算法学到的表征（Kmeans）。给定输入向量的表征是一个one-hot编码（识别出哪个聚类中心最佳表示输入）。用决策树的情形似乎好一点，因为每个给定输入是和叶子上的one-hot编码相联系，这选择了相关的祖先（从根到节点的路径）。不幸的是，代表不同区域的数目（和树叶的数目相等）仍然与明确它的参数数目呈线性关系。【(Bengio and Delalleau, 2011)】
重复使用的概念，不仅解释了distributed representation的强大，也是位于深度学习背后理论优势的中心，即构建多层表征或者学习特征的层次。回路的深度是从输入节点到输出节点的长度。形式上，可以通过改变每一个节点计算内容的定义来改变给定回路的深度，但只有一个常数因子。我们允许在每个节点的计算包括：权值和、乘积、人工神经模型（比如在放射变换顶上的一个单调非线性）、核计算以及逻辑门。理论结果清晰地展示了深度表征的函数家族会以指数优于不够深的表征。【(H˚astad, 1986;H˚astad and Goldmann, 1991;Bengio et al.,2006a;Bengio and LeCun,2007;Bengio and Delalleau,2011)】如果同样函数家族能够被更少参数表示（或者被小点的VC维度更精确表示），那么学习理论建议它能够被更少样本习得，这会提高计算效率和统计效率。
另一个进行特征学习和深度学习的重要驱动是他们能够被未标记样本完成，只要和问题相关（被预测的类别）的参数在输入分布中某种程度上是显著的。这在流行假设中是正确的，流行假设声称自然类别和其他人类感兴趣的高级别概念在输入空间（流形）中靠近分布集中的低维度区域是有联系的，并且不同类别流形很好被低密度区域所划分。所以，特征学习以及深度学习和无监督学习有着密切的联系，并且能够被开发用到半监督学习（只有少数样本被标记）、迁移学习和多任务学习中（目的是泛化到新类别和任务）。隐含的假设是许多隐含因子跨类别或任务是共享的。
2006年，特征学习和深度学习发生了重大突破【(Hinton et al., 2006;Bengio et al.,2007;Ranzato et al.,2007)】，这些已被广泛的回顾和讨论在【Bengio(2009)】。一个中心思想，指的是逐层贪心无监督预训练，是一次学习特征的一个层次，利用无监督特征学习来学习每层的新变换，该层是由之前已经学到的变换组成。本质上，每次无监督特征学习的迭代增加了深度神经网络的一层权值。最后，层集合组合在一起来初始化深度监督预测器，比如神经网络分类器；或者是一个深度生成模型，比如深度玻尔兹曼机器。【(Salakhutdinov and Hinton,2009a)】
本文是关于特征学习算法，能够堆积达到那个目的，因为它从经验上观察到这种逐层特征提取堆积通常取得更好的表征，<font color=red>比如从分类错误的角度【(Larochelle et al.,2009b;Erhan et al.,2010b)】，概率模型生成的样本质量的角度【(Salakhutdinov and Hinton,2009a)】或者是从学到特征不变性质的角度【(Goodfellow et al.,2009)】。</font>
在所有特征提取算法中，主成分分析（PCA）【(Pearson,1901;Hotelling,1933)】可能是最老也是最广泛运用的。对于输入\\(x\in\mathbb{R}^{d_x}\\)它学习一个线性变换\\(h=f(x)=W^{T}x+b\\)，其中\\(d_x\times d_h\\)矩阵\\(W\\)形成训练集最大方差\\(d_h\\)正交方向上的正交基。结果是消除相关的\\(d_h\\)特征（表征h的组成成分）。有趣的是，在最近非线性特征学习技术发展过程中，提出了三种不同的视角来重新解读PCA。a) 和概率模型相关（第二章节），比如概率PCA、因素分析和传统的多变量高斯分布（协方差矩阵的主要特征向量是主要成分）；b) 它学到的表征本质上和基本线性编码器是一样的（第三章节）；c) 它可被看成是流形学习中的简单线性公式，也就是描绘了输入空间数据紧密的低维区域。因此提到PCA，读者应当将这些不同视角记在脑中。不幸的是，线性特征的表现力是有限的：他们不能通过堆积来形成更深更抽象的表征，因为线性计算的成分组成了另一个线性计算。这里，我们关注最近提取非线性特征且能够堆积构建深度网络的算法，虽然一些作者只是简单地在学到的单层线性映射中插入非线性【(Le et al.,2011c;Chen et al.,2012)】。另一个特征提取技术的大家族，由于空间限制本文并没有覆盖到任何细节的是ICA【(Jutten and Herault,1991;Comon,1994;Bell and Sejnowski,1997)】。相反，我们建议读者读【Hyvarinen et al.(2001a);Hyvarinen et al.(2009)】。值得注意的是，尽管在简单案例中（完整，无噪声）ICA产生线性特征，但是更多一般的案例中，它相当于是非高斯独立隐含变量的线性生成模型，与稀疏编码类似（2.1.3节）,这会产生非线性特征。所以ICA和它的变种如Independent Subspace Analysis【(Hyvarinen and Hoyer,2000)】和Topographic ICA【(Hyvarinen et al.,2001b)】能够也已经被用来建立深度网络【(Le et al.,2010,2011c)】：看8.2节。获得独立成分的概念表面上也和我们申明的通过深度网络解决隐含解释型因素的目标相似。但是，对于复杂现实分布，两者的关系能够通过线性转换充分描述是值得怀疑的，这两者是：真实的独立隐含因素和观察到的高维数据。
本文新的贡献是它提出了一个新的概率框架，其包含了传统的基于似然概率的概率模型（第二章节）以及基于重构的模型如自动编码的变种（第三章节）。我们把这个新框架命名为JEPADA，Joint Energy in PArameters and DAta：基本思想是将基于重建的模型训练准则看作是一个联合无向模型（链接数据和参数）的能量方程，把两者都边缘化的分区功能。
本文也提了许多问题，在这里讨论但未完全解决。
* 什么是好的表征？
* 学习这样的表征，好的准则是什么？
* 我们怎么评估表征学习算法的质量？
* 对于非概率特征学习是否有概率性的解释？比如自动编码变种和可预测的系数分解【(Kavukcuoglu et al.,2008)】。我们是否能从相应模型采样？
* 概率和非概率模型的优势和劣势分别是什么？
* 学习到的表征是否一定是低维的？（就比如在PCA中）
* 我们是否能以某种方式将输入映射为表征，即考虑为不同解释性因素的影响作出解释，以更高昂的计算代价？
* 将表征堆积成深度架构所增加的效力是否值得额外的努力？
* 全局优化深度架构为什么如此困难？原因是什么？
* 一些学习表征的方法（尤其是深度）成功背后的原因是什么？

##2 概率模型
从概率模型的视角，特征学习问题可以被解读为：尝试恢复一个节约的隐含自由变量集，来描述观察数据的分布。我们可以将隐含变量\\(h\\)和可见变量\\(x\\)联合空间的任何概率模型表达为\\(p(x,h)\\)。特征值可设想为推论过程的结果，这个推论过程是指决定给定数据中隐含变量的概率分布，即\\(p(h|x)\\)，通常也指后验概率。学习可设想为估计一系列模型参数，来最大化训练数据关于隐含变量分布的似然性。概率图模型形式主义给我们两种可能建模范例，我们从中可以考虑推断隐含变量的问题：有向和无向图模型。这两范例的关键区别因素是他们联合分布\\(p(x,h)\\)的参数化本质。有向和无向模型的选择对性质和推断与学习算法过程的计算代价有很大的影响。
###2.1 有向图模型
有向隐含因素变量参数化可以通过联合分布的分解，\\(p(x,h)=p(x|h)\times p(h)，包含先验\\(p(h)\\)和一个似然\\(p(x|h)\\)以隐含变量\\(h\\)来描述观察数据\\(x\\)。能够用这种分解来解释的无监督特征学习模型包括：PCA，稀疏编码，sigmoid信念网络和最新介绍的spike-and-slab稀疏编码模型。
####2.1.1 Explaining Away（解释剔除）
在隐含因素模型内容中，有向图模型的形式通常导致一个重要的性质，也就是explaining away：给定事件的观察量，一个事件的先验独立因果可能是非独立的。隐含因素模型一般能够被解释为隐含因果模型，其中\\(h\\)激活导致观察量\\(x\\)。这使得先验独立的\\(h\\)为非独立的。作为恢复\\(h\\)的后验分布的结果:\\(p(h|x)\\)(我们用它作为特征表征的基础)通常是计算挑战性而且是完全棘手的，尤其当h是离散的。
阐明这种现象的经典例子是：想象你正在离家度假，你接到了来自在你家安装安全系统的公司，他们告诉你警报已被激活。你开始担心家里被盗窃，但是然后你在收音机里听说你家附近报道有小地震。如果你恰巧根据先验知识知道地震可能造成你家警报系统激活，那么突然你就放松了，自信你家很有可能没有被盗窃。
这个例子阐述了观察量（警报激活）是怎么使得另外两个完全独立的原因（被盗窃和地震）成为相关的，在这个例子里，依赖性是两者相互排斥。因为被盗和地震都是小概率事件而且都能激活警报，所以看到一个原因自然就解释剔除了另一个。这个例子不仅阐明了观察量怎么使得原因成为统计独立，也阐明了解释剔除的功用。它提升了从观察量预测未见或者隐含事件的预测。回到隐含因素模型，尽管当我们试图从\\(h\\)恢复后验概率会面临计算阻碍，解释剔除提供了一个节俭的\\(p(h|x)\\),成为一个特征编码组合相当有用的性质。如果有人把表征看作由不同特征检测器和估计的观察输入性质组成，那么允许不同特征对抗和合作来解释初入是有用的。这自然能通过有向图模型达成，也能通过无向图模型实现（见章节2.2），例如玻尔兹曼
##3 正则化自动编码器